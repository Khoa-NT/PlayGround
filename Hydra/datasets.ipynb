{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs):\n",
    "        'Initialization'\n",
    "#         self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = ID\n",
    "#         y = self.labels[ID]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "\n",
    "def get_path_files(fdir: \"path to folder\" = \"\", ftype: \"file type\" = \"*\", do_sort = False , only_filename = False) -> \"Paths[file_path]\":\n",
    "    \"\"\" Glob all file in fdir and return a sorted list\"\"\"\n",
    "    if only_filename:\n",
    "        list_files_path = [str(x.name) for x in Path(fdir).glob(ftype)]\n",
    "    else:\n",
    "        list_files_path = [str(x) for x in Path(fdir).glob(ftype)]\n",
    "    if do_sort:\n",
    "        list_files_path = natsorted(list_files_path)\n",
    "    return list_files_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/0000.tif', 'data/0001.tif', 'data/0002.tif', 'data/0003.tif', 'data/0004.tif', 'data/0005.tif', 'data/0006.tif', 'data/0007.tif', 'data/0008.tif', 'data/0009.tif', 'data/0010.tif', 'data/0011.tif', 'data/0012.tif', 'data/0013.tif', 'data/0014.tif', 'data/0015.tif', 'data/0016.tif', 'data/0017.tif', 'data/0018.tif', 'data/0019.tif', 'data/0020.tif', 'data/0021.tif', 'data/0022.tif', 'data/0023.tif', 'data/0024.tif', 'data/0025.tif', 'data/0026.tif', 'data/0027.tif', 'data/0028.tif', 'data/0029.tif', 'data/0030.tif', 'data/0031.tif', 'data/0032.tif', 'data/0033.tif', 'data/0034.tif', 'data/0035.tif', 'data/0036.tif', 'data/0037.tif', 'data/0038.tif', 'data/0039.tif', 'data/0040.tif', 'data/0041.tif', 'data/0042.tif', 'data/0043.tif', 'data/0044.tif', 'data/0045.tif', 'data/0046.tif', 'data/0047.tif', 'data/0048.tif', 'data/0049.tif', 'data/0050.tif', 'data/0051.tif', 'data/0052.tif', 'data/0053.tif', 'data/0054.tif', 'data/0055.tif', 'data/0056.tif', 'data/0057.tif', 'data/0058.tif', 'data/0059.tif', 'data/0060.tif', 'data/0061.tif', 'data/0062.tif', 'data/0063.tif', 'data/0064.tif', 'data/0065.tif', 'data/0066.tif', 'data/0067.tif', 'data/0068.tif', 'data/0069.tif', 'data/0070.tif', 'data/0071.tif', 'data/0072.tif', 'data/0073.tif', 'data/0074.tif', 'data/0075.tif', 'data/0076.tif', 'data/0077.tif', 'data/0078.tif', 'data/0079.tif', 'data/0080.tif', 'data/0081.tif', 'data/0082.tif', 'data/0083.tif', 'data/0084.tif', 'data/0085.tif', 'data/0086.tif', 'data/0087.tif', 'data/0088.tif', 'data/0089.tif', 'data/0090.tif', 'data/0091.tif', 'data/0092.tif', 'data/0093.tif', 'data/0094.tif', 'data/0095.tif', 'data/0096.tif', 'data/0097.tif', 'data/0098.tif', 'data/0099.tif']\n",
      "['data/0080.tif', 'data/0084.tif', 'data/0033.tif', 'data/0081.tif', 'data/0093.tif', 'data/0017.tif', 'data/0036.tif', 'data/0082.tif', 'data/0069.tif', 'data/0065.tif', 'data/0092.tif', 'data/0039.tif', 'data/0056.tif', 'data/0052.tif', 'data/0051.tif', 'data/0032.tif', 'data/0031.tif', 'data/0044.tif', 'data/0078.tif', 'data/0010.tif', 'data/0002.tif', 'data/0073.tif', 'data/0097.tif', 'data/0062.tif', 'data/0019.tif', 'data/0035.tif', 'data/0094.tif', 'data/0027.tif', 'data/0046.tif', 'data/0038.tif', 'data/0067.tif', 'data/0099.tif', 'data/0054.tif', 'data/0095.tif', 'data/0088.tif', 'data/0040.tif', 'data/0048.tif', 'data/0059.tif', 'data/0023.tif', 'data/0034.tif', 'data/0086.tif', 'data/0053.tif', 'data/0077.tif', 'data/0015.tif', 'data/0083.tif', 'data/0041.tif', 'data/0045.tif', 'data/0091.tif', 'data/0026.tif', 'data/0098.tif', 'data/0043.tif', 'data/0055.tif', 'data/0024.tif', 'data/0004.tif', 'data/0058.tif', 'data/0049.tif', 'data/0021.tif', 'data/0087.tif', 'data/0003.tif', 'data/0074.tif', 'data/0030.tif', 'data/0066.tif', 'data/0070.tif', 'data/0042.tif', 'data/0047.tif', 'data/0089.tif', 'data/0008.tif', 'data/0060.tif', 'data/0000.tif', 'data/0090.tif', 'data/0057.tif', 'data/0022.tif', 'data/0061.tif', 'data/0063.tif', 'data/0007.tif', 'data/0096.tif', 'data/0013.tif', 'data/0068.tif', 'data/0085.tif', 'data/0014.tif', 'data/0029.tif', 'data/0028.tif', 'data/0011.tif', 'data/0018.tif', 'data/0020.tif', 'data/0050.tif', 'data/0025.tif', 'data/0006.tif', 'data/0071.tif', 'data/0076.tif', 'data/0001.tif', 'data/0016.tif', 'data/0064.tif', 'data/0079.tif', 'data/0005.tif', 'data/0075.tif', 'data/0009.tif', 'data/0072.tif', 'data/0012.tif', 'data/0037.tif']\n",
      "len(list_path): 100\n",
      "len(train_names): 80\n",
      "len(val_names): 20\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "\n",
    "list_path = get_path_files(\"data\")\n",
    "\n",
    "print(list_path)\n",
    "\n",
    "rng.shuffle(list_path)\n",
    "print(list_path)\n",
    "\n",
    "train_names = list_path[:int(len(list_path)*0.8)]\n",
    "val_names = list_path[len(train_names):]\n",
    "\n",
    "print(f\"len(list_path): {len(list_path)}\")\n",
    "print(f\"len(train_names): {len(train_names)}\")\n",
    "print(f\"len(val_names): {len(val_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/0057.tif', 'data/0005.tif', 'data/0076.tif', 'data/0082.tif', 'data/0073.tif', 'data/0024.tif', 'data/0085.tif', 'data/0006.tif', 'data/0051.tif', 'data/0071.tif', 'data/0098.tif', 'data/0099.tif', 'data/0032.tif', 'data/0043.tif', 'data/0053.tif', 'data/0083.tif', 'data/0002.tif', 'data/0045.tif', 'data/0018.tif', 'data/0033.tif', 'data/0031.tif', 'data/0007.tif', 'data/0070.tif', 'data/0074.tif', 'data/0049.tif', 'data/0094.tif', 'data/0044.tif', 'data/0067.tif', 'data/0075.tif', 'data/0091.tif', 'data/0066.tif', 'data/0011.tif', 'data/0093.tif', 'data/0022.tif', 'data/0086.tif', 'data/0020.tif', 'data/0056.tif', 'data/0010.tif', 'data/0055.tif', 'data/0004.tif', 'data/0052.tif', 'data/0017.tif', 'data/0048.tif', 'data/0037.tif', 'data/0060.tif', 'data/0021.tif', 'data/0025.tif', 'data/0097.tif', 'data/0088.tif', 'data/0030.tif', 'data/0009.tif', 'data/0014.tif', 'data/0028.tif', 'data/0034.tif', 'data/0059.tif', 'data/0096.tif', 'data/0078.tif', 'data/0036.tif', 'data/0065.tif', 'data/0015.tif', 'data/0077.tif', 'data/0042.tif', 'data/0013.tif', 'data/0054.tif']\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.utils import data\n",
    "\n",
    "# from my_classes import Dataset\n",
    "\n",
    "\n",
    "# # CUDA for PyTorch\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "max_epochs = 100\n",
    "\n",
    "# Datasets\n",
    "partition = get_path_files(\"data\")\n",
    "# labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch in training_generator:\n",
    "        # Transfer to GPU\n",
    "        print(local_batch)\n",
    "        print(len(local_batch))\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_app\n",
      "my_classes\n",
      "pytorch_script\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path().cwd().glob(\"*.py\")\n",
    "\n",
    "for i_path in path:\n",
    "    print(i_path.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Alexandrite/khoa/github_test/Hydra/data\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = f\"{Path().cwd() / 'data'}\"\n",
    "\n",
    "print(path)\n",
    "print(type(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to register operator torchvision::_new_empty_tensor_op.                            The symbolic name must match the format Domain::Name,                            and sould start with a letter and contain only                            alphanumerical characters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6dd351122000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/models/detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmask_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeypoint_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/models/detection/faster_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmisc_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_register_onnx_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/ops/_register_onnx_ops.py\u001b[0m in \u001b[0;36m_register_custom_op\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mregister_custom_op_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torchvision::roi_align'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mregister_custom_op_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torchvision::roi_pool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mregister_custom_op_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torchvision::_new_empty_tensor_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_empty_tensor_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mregister_custom_op_symbolic\u001b[0;34m(symbolic_name, symbolic_fn, opset_version)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregister_custom_op_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_custom_op_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mregister_custom_op_symbolic\u001b[0;34m(symbolic_name, symbolic_fn, opset_version)\u001b[0m\n\u001b[1;32m    791\u001b[0m                            \u001b[0;32mand\u001b[0m \u001b[0msould\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0monly\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                            \u001b[0malphanumerical\u001b[0m \u001b[0mcharacters\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                            .format(symbolic_name))\n\u001b[0m\u001b[1;32m    794\u001b[0m     \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'::'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0munaccepted_domain_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"aten\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to register operator torchvision::_new_empty_tensor_op.                            The symbolic name must match the format Domain::Name,                            and sould start with a letter and contain only                            alphanumerical characters"
     ]
    }
   ],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
