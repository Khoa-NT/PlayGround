agent:
  name: SegRL
  cls: agents.segRL.SegRLAgent

  continuous: false
  lstm_feats: 0
  shared_optimizer: false

  mid_step: false
  done_step: true
  obs:
    len_observation_shape: 2 # RGB + label + seed
    observation_shape: ???

  tau: 1.0
  entropy_alpha: 0.05 # explore or exploit
  gamma: 0.98 # reward decay
  fixed_percent: 0.2 # improved percent thres / good

  max_step: 6
  num_steps: 6
  num_actions: 26

  env:
    name: SegRL_env
    cls: graphs.env.SegRLEnv.segRL_env

    reward:
      min: 0.1
      medium: 0.5
      max: 1.0
      pick_correct: 1.0
      fixed_percent_correct: 0.5
      seg_loss_correct: 0.5

    penalty:
      min: 0.0
      medium: 0.1
      max: 0.3
      repick_old_act: 0.1
      pick_wrong: 0.1
      fixed_percent_wrong: 0.1
      seg_loss_wrong: 0.0







