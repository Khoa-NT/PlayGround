agent:
  name: Locator
  cls: agents.locator.LocatorAgent

  continuous: false
  lstm_feats: 0
  shared_optimizer: false

  mid_step: true
  done_step: false

  len_observation_shape: 2 # RGB + label + seed
  observation_shape: ???

  tau: 1.0
  entropy_alpha: 0.05 # explore or exploit
  gamma: 0.98 # reward decay
  fixed_percent: 0.2 # improved percent thres / good

  max_step: 6
  num_steps: 6
  num_actions: 26

  init_model: deeplabv3_resnet101

  env:
    name: Locator_env
    cls: graphs.env.LocatorEnv.locator_env
    reward:
      min: 0.1
      medium: 0.5
      max: 1.0
      pick_correct: 1.0
      fixed_percent_correct: 0.5
    penalty:
      min: 0.0
      medium: 0.1
      max: 0.3
      repick_old_act: 0.1
      pick_wrong: 0.1
      fixed_percent_wrong: 0.1







